{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lending Club Dataset is used for this project: a large US peer-to-peer lending company. There are several different versions of this dataset. We have used the updated dataset (version 2), which is available on kaggle: https://www.kaggle.com/wendykan/lending-club-loan-data/\n",
    "\n",
    "We divided the data into two periods because we assume that some data are available at the moment when we need to build Expected Loss models, and some data comes from applications after. Later, we investigate whether the applications we have after we built the Probability of Default (PD) model have similar characteristics with the applications we used to build the PD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13134\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (19,47,55,112,123,124,125,128,129,130,133,139,140,141) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loan = r'F:\\Data Analysis\\Springboard\\Data Science Career Track\\Projects\\Capstone 2\\lending club loan data_version 2\\loan.csv'\n",
    "\n",
    "loan_data_backup = pd.read_csv(loan)\n",
    "\n",
    "loan_data = loan_data_backup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.56</td>\n",
       "      <td>84.92</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>18.94</td>\n",
       "      <td>777.23</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>17.97</td>\n",
       "      <td>180.69</td>\n",
       "      <td>D</td>\n",
       "      <td>D1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>18.94</td>\n",
       "      <td>146.51</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>16.14</td>\n",
       "      <td>731.78</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0 NaN        NaN       2500         2500           2500.0   36 months   \n",
       "1 NaN        NaN      30000        30000          30000.0   60 months   \n",
       "2 NaN        NaN       5000         5000           5000.0   36 months   \n",
       "3 NaN        NaN       4000         4000           4000.0   36 months   \n",
       "4 NaN        NaN      30000        30000          30000.0   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
       "0     13.56        84.92     C        C1  ...                            NaN   \n",
       "1     18.94       777.23     D        D2  ...                            NaN   \n",
       "2     17.97       180.69     D        D1  ...                            NaN   \n",
       "3     18.94       146.51     D        D2  ...                            NaN   \n",
       "4     16.14       731.78     C        C4  ...                            NaN   \n",
       "\n",
       "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
       "0                          NaN                Cash                     N   \n",
       "1                          NaN                Cash                     N   \n",
       "2                          NaN                Cash                     N   \n",
       "3                          NaN                Cash                     N   \n",
       "4                          NaN                Cash                     N   \n",
       "\n",
       "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
       "0                       NaN               NaN             NaN   \n",
       "1                       NaN               NaN             NaN   \n",
       "2                       NaN               NaN             NaN   \n",
       "3                       NaN               NaN             NaN   \n",
       "4                       NaN               NaN             NaN   \n",
       "\n",
       "  settlement_amount  settlement_percentage settlement_term  \n",
       "0               NaN                    NaN             NaN  \n",
       "1               NaN                    NaN             NaN  \n",
       "2               NaN                    NaN             NaN  \n",
       "3               NaN                    NaN             NaN  \n",
       "4               NaN                    NaN             NaN  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2260663</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>14.08</td>\n",
       "      <td>279.72</td>\n",
       "      <td>C</td>\n",
       "      <td>C3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260664</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>25.82</td>\n",
       "      <td>358.01</td>\n",
       "      <td>E</td>\n",
       "      <td>E4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260665</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>11.99</td>\n",
       "      <td>332.10</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260666</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>21.45</td>\n",
       "      <td>327.69</td>\n",
       "      <td>D</td>\n",
       "      <td>D5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260667</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16550</td>\n",
       "      <td>16550</td>\n",
       "      <td>16550.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>21.45</td>\n",
       "      <td>451.94</td>\n",
       "      <td>D</td>\n",
       "      <td>D5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "2260663 NaN        NaN      12000        12000          12000.0   60 months   \n",
       "2260664 NaN        NaN      12000        12000          12000.0   60 months   \n",
       "2260665 NaN        NaN      10000        10000          10000.0   36 months   \n",
       "2260666 NaN        NaN      12000        12000          12000.0   60 months   \n",
       "2260667 NaN        NaN      16550        16550          16550.0   60 months   \n",
       "\n",
       "         int_rate  installment grade sub_grade  ...  \\\n",
       "2260663     14.08       279.72     C        C3  ...   \n",
       "2260664     25.82       358.01     E        E4  ...   \n",
       "2260665     11.99       332.10     B        B5  ...   \n",
       "2260666     21.45       327.69     D        D5  ...   \n",
       "2260667     21.45       451.94     D        D5  ...   \n",
       "\n",
       "        hardship_payoff_balance_amount hardship_last_payment_amount  \\\n",
       "2260663                            NaN                          NaN   \n",
       "2260664                            NaN                          NaN   \n",
       "2260665                            NaN                          NaN   \n",
       "2260666                            NaN                          NaN   \n",
       "2260667                            NaN                          NaN   \n",
       "\n",
       "        disbursement_method  debt_settlement_flag debt_settlement_flag_date  \\\n",
       "2260663                Cash                     N                       NaN   \n",
       "2260664                Cash                     N                       NaN   \n",
       "2260665                Cash                     N                       NaN   \n",
       "2260666                Cash                     N                       NaN   \n",
       "2260667                Cash                     N                       NaN   \n",
       "\n",
       "        settlement_status settlement_date settlement_amount  \\\n",
       "2260663               NaN             NaN               NaN   \n",
       "2260664               NaN             NaN               NaN   \n",
       "2260665               NaN             NaN               NaN   \n",
       "2260666               NaN             NaN               NaN   \n",
       "2260667               NaN             NaN               NaN   \n",
       "\n",
       "         settlement_percentage settlement_term  \n",
       "2260663                    NaN             NaN  \n",
       "2260664                    NaN             NaN  \n",
       "2260665                    NaN             NaN  \n",
       "2260666                    NaN             NaN  \n",
       "2260667                    NaN             NaN  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display all columns\n",
    "#pd.options.display.max_columns = None\n",
    "#loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display all rows\n",
    "#pd.options.display.max_rows = None\n",
    "#loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
       "       'emp_title', 'emp_length', 'home_ownership', 'annual_inc',\n",
       "       'verification_status', 'issue_d', 'loan_status', 'pymnt_plan',\n",
       "       'url', 'desc', 'purpose', 'title', 'zip_code', 'addr_state', 'dti',\n",
       "       'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths',\n",
       "       'mths_since_last_delinq', 'mths_since_last_record', 'open_acc',\n",
       "       'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
       "       'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
       "       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
       "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
       "       'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d',\n",
       "       'last_credit_pull_d', 'collections_12_mths_ex_med',\n",
       "       'mths_since_last_major_derog', 'policy_code', 'application_type',\n",
       "       'annual_inc_joint', 'dti_joint', 'verification_status_joint',\n",
       "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
       "       'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
       "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m',\n",
       "       'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi',\n",
       "       'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths',\n",
       "       'avg_cur_bal', 'bc_open_to_buy', 'bc_util',\n",
       "       'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct',\n",
       "       'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
       "       'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq',\n",
       "       'mths_since_recent_inq', 'mths_since_recent_revol_delinq',\n",
       "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
       "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
       "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats',\n",
       "       'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m',\n",
       "       'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75',\n",
       "       'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim',\n",
       "       'total_bal_ex_mort', 'total_bc_limit',\n",
       "       'total_il_high_credit_limit', 'revol_bal_joint',\n",
       "       'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths',\n",
       "       'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util',\n",
       "       'sec_app_open_act_il', 'sec_app_num_rev_accts',\n",
       "       'sec_app_chargeoff_within_12_mths',\n",
       "       'sec_app_collections_12_mths_ex_med',\n",
       "       'sec_app_mths_since_last_major_derog', 'hardship_flag',\n",
       "       'hardship_type', 'hardship_reason', 'hardship_status',\n",
       "       'deferral_term', 'hardship_amount', 'hardship_start_date',\n",
       "       'hardship_end_date', 'payment_plan_start_date', 'hardship_length',\n",
       "       'hardship_dpd', 'hardship_loan_status',\n",
       "       'orig_projected_additional_accrued_interest',\n",
       "       'hardship_payoff_balance_amount', 'hardship_last_payment_amount',\n",
       "       'disbursement_method', 'debt_settlement_flag',\n",
       "       'debt_settlement_flag_date', 'settlement_status',\n",
       "       'settlement_date', 'settlement_amount', 'settlement_percentage',\n",
       "       'settlement_term'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2260668 entries, 0 to 2260667\n",
      "Columns: 145 entries, id to settlement_term\n",
      "dtypes: float64(105), int64(4), object(36)\n",
      "memory usage: 2.4+ GB\n"
     ]
    }
   ],
   "source": [
    "# Displays column names, complete (non-missing) cases per column, and datatype per column.\n",
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       float64\n",
       "member_id                float64\n",
       "loan_amnt                  int64\n",
       "funded_amnt                int64\n",
       "funded_amnt_inv          float64\n",
       "                          ...   \n",
       "settlement_status         object\n",
       "settlement_date           object\n",
       "settlement_amount        float64\n",
       "settlement_percentage    float64\n",
       "settlement_term          float64\n",
       "Length: 145, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260668, 145)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing few continuous variables: `emp_length`, `earlist_cr_line`, `term`, `issue_d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10+ years', '6 years', '4 years', '< 1 year', '2 years',\n",
       "       '9 years', nan, '5 years', '3 years', '7 years', '1 year',\n",
       "       '8 years'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display unique values of a column.\n",
    "loan_data['emp_length'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `emp_length` has four things we have to remove to be able to convert it into an integer:\n",
    "    1.`+ years`\n",
    "    2.`< 1 year`\n",
    "    3.`nan`\n",
    "    4.` years` and `year`  (space years and space year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting the employment lenght from object into integer. We will store the new variable as 'employment length int'\n",
    "\n",
    "# 1.Assign the new ‘employment length int’ to be equal to the ‘employment length’ variable with the string ‘+ years’\n",
    "loan_data['emp_length_int'] = loan_data['emp_length'].str.replace('\\+ years', '')\n",
    "\n",
    "# 2Replace the whole string ‘less than 1 year’ with the string ‘0’.\n",
    "loan_data['emp_length_int'] = loan_data['emp_length_int'].str.replace('< 1 year', str(0))\n",
    "\n",
    "# 3.Replace the ‘n/a’ string with the string ‘0’.\n",
    "loan_data['emp_length_int'] = loan_data['emp_length_int'].str.replace('n/a',  str(0))\n",
    "\n",
    "# 4.Replace the string ‘space years’  and 'space year' with nothing.\n",
    "loan_data['emp_length_int'] = loan_data['emp_length_int'].str.replace(' years', '')\n",
    "loan_data['emp_length_int'] = loan_data['emp_length_int'].str.replace(' year', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks the datatype of a single element of a column.\n",
    "type(loan_data['emp_length_int'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transform it into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['emp_length_int'] = pd.to_numeric(loan_data['emp_length_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loan_data['emp_length_int'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is `earliest credit line`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next is 'earliest credit line'\n",
    "#loan_data['earliest_cr_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loan_data['earliest_cr_line'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'earliest credit line' is a date variable. We can extracts the date and the time from a string variable that is in a given format.\n",
    "#loan_data['earliest_cr_line_date'] = pd.to_datetime(loan_data['earliest_cr_line'], format= '%b-%Y')\n",
    "\n",
    "#loan_data['earliest_cr_line_date'] = loan_data['earliest_cr_line'].apply(pd.to_datetime)\n",
    "\n",
    "loan_data['earliest_cr_line_date'] = pd.to_datetime(loan_data['earliest_cr_line'], infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loan_data['earliest_cr_line'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          6088 days\n",
       "1         11141 days\n",
       "2          2436 days\n",
       "3          4321 days\n",
       "4          6209 days\n",
       "             ...    \n",
       "2260663    5083 days\n",
       "2260664    5389 days\n",
       "2260665    8339 days\n",
       "2260666    5267 days\n",
       "2260667    1340 days\n",
       "Name: earliest_cr_line_date, Length: 2260668, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the difference between two dates and times.\n",
    "pd.to_datetime('2017-12-01') - loan_data['earliest_cr_line_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we are now in December 2017.We calculate the difference between two dates in months, turn it to numeric datatype and round it.\n",
    "# We save the result in a new variable.\n",
    "loan_data['mths_since_earliest_cr_line'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - loan_data['earliest_cr_line_date']) / np.timedelta64(1, 'M')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.260639e+06\n",
       "mean     2.156891e+02\n",
       "std      9.416722e+01\n",
       "min      2.500000e+01\n",
       "25%      1.510000e+02\n",
       "50%      2.000000e+02\n",
       "75%      2.650000e+02\n",
       "max      1.017000e+03\n",
       "Name: mths_since_earliest_cr_line, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows some descriptive statisics for the values of a column.\n",
    "# Dates from 1969 and before are not being converted well, i.e., they have become 2069 and similar,\n",
    "# and negative differences are being calculated.\n",
    "loan_data['mths_since_earliest_cr_line'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>earliest_cr_line_date</th>\n",
       "      <th>mths_since_earliest_cr_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [earliest_cr_line, earliest_cr_line_date, mths_since_earliest_cr_line]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# We take three columns from the dataframe. Then, we display them only for the rows where a variable has negative value.\n",
    "loan_data.loc[: , ['earliest_cr_line', 'earliest_cr_line_date', 'mths_since_earliest_cr_line']][loan_data['mths_since_earliest_cr_line'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13134\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# We set the rows that had negative differences to the maximum value.\n",
    "loan_data['mths_since_earliest_cr_line'][loan_data['mths_since_earliest_cr_line'] < 0] = loan_data['mths_since_earliest_cr_line'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates and shows the minimum value of a column.\n",
    "min(loan_data['mths_since_earliest_cr_line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next variable to pre-process is `term`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows some descriptive statisics for the values of a column.\n",
    "loan_data['term'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace a string with another string, in this case, with an empty strng (i.e. with nothing).\n",
    "loan_data['term_int'] = loan_data['term'].str.replace(' months', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loan_data['term_int'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remplace a string from a variable with another string, in this case, with an empty strng (i.e. with nothing).\n",
    "# We turn the result to numeric datatype and save it in another variable.\n",
    "loan_data['term_int'] = pd.to_numeric(loan_data['term'].str.replace(' months', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks the datatype of a single element of a column.\n",
    "type(loan_data['term_int'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next variable to pre-process is `issue_d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['issue_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we are now in December 2017\n",
    "# Extracts the date and the time from a string variable that is in a given format.\n",
    "loan_data['issue_d_date'] = pd.to_datetime(loan_data['issue_d'], infer_datetime_format=True)\n",
    "\n",
    "# We calculate the difference between two dates in months, turn it to numeric datatype and round it.\n",
    "# We save the result in a new variable.\n",
    "loan_data['mths_since_issue_d'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - loan_data['issue_d_date']) / np.timedelta64(1, 'M')))\n",
    "\n",
    "# Shows some descriptive statisics for the values of a column.\n",
    "loan_data['mths_since_issue_d'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing few discrete/categorical variables**\n",
    "\n",
    "**Variables: `grade`, `sub_grade`, `home_owenership`, `purpose`, `addr_state`, `initial_list_status`. We are not going to use `sub_grade`, as it overlaps with grade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays column names, complete (non-missing) cases per column, and datatype per column.\n",
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create dummy variables from all 8 original independent variables, and save them into a list.\n",
    "\n",
    "loan_data_dummies = [pd.get_dummies(loan_data['grade'], prefix = 'grade', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['sub_grade'], prefix = 'sub_grade', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['home_ownership'], prefix = 'home_ownership', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['verification_status'], prefix = 'verification_status', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['loan_status'], prefix = 'loan_status', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['purpose'], prefix = 'purpose', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['addr_state'], prefix = 'addr_state', prefix_sep = ':'),\n",
    "                     pd.get_dummies(loan_data['initial_list_status'], prefix = 'initial_list_status', prefix_sep = ':')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We concatenate the dummy variables and this turns them into a dataframe.\n",
    "loan_data_dummies = pd.concat(loan_data_dummies, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loan_data_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We concatenate the original loan_data with the dataframe with dummy variables, along the columns. \n",
    "loan_data = pd.concat([loan_data, loan_data_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays all column names.\n",
    "loan_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING\n",
    "\n",
    "**Checking and handling missing and NA values**\n",
    "\n",
    "We will be using these variables in our analysis. Let's check for their missing values and fill them: `annual_inc`, `delinq_2yrs`, `inq_last_6mths`, `open_acc`, `pub_rec`, `total_acc`, `acc_now_delinq`, `total_rev_hi_lim`, `emp_length_int`, and `mths_since_earliest_cr_line`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns 'False' if a value is not missing and 'True' if a value is missing, for each value in a dataframe.\n",
    "loan_data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "#pd.options.display.max_rows = None\n",
    "#loan_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "#pd.options.display.max_columns = None\n",
    "#loan_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One way to deal with missing values is to remove all observations(rows) where we have missing values. Another way to deal with missing values is to impute them**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with `total_rev_hi_lim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Total revolving high credit/ credit limit' will most likely be equal to 'funded_amnt'.\n",
    "#So we replace the missing values in that with the values from funded_amnt\n",
    "loan_data['total_rev_hi_lim'].fillna(loan_data['funded_amnt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see if there are still any missing values\n",
    "loan_data['total_rev_hi_lim'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do for `annual_inc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will fill the missing values with the mean value of the non-missing values for 'annual_inc'.\n",
    "loan_data['annual_inc'].fillna(loan_data['annual_inc'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['annual_inc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the others, we will fill them with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill the missing values with zeroes.\n",
    "loan_data['mths_since_earliest_cr_line'].fillna(0, inplace=True)\n",
    "loan_data['acc_now_delinq'].fillna(0, inplace=True)\n",
    "loan_data['total_acc'].fillna(0, inplace=True)\n",
    "loan_data['pub_rec'].fillna(0, inplace=True)\n",
    "loan_data['open_acc'].fillna(0, inplace=True)\n",
    "loan_data['inq_last_6mths'].fillna(0, inplace=True)\n",
    "loan_data['delinq_2yrs'].fillna(0, inplace=True)\n",
    "loan_data['emp_length_int'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of Default (PD) model\n",
    "\n",
    "**Data Preparations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dependent Variable will be Good/ Bad (Default) loan. The definition used here is that, accounts are considered as default (bad loan) if the borrower has been 90 days past due on the loan. Also, a borrower is considered default if the borrower commits fraud. The variable `loan_status` is used to determine if a customer has defaulted or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays unique values of loan_status column\n",
    "loan_data['loan_status'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the number of observations for each unique value of a variable\n",
    "loan_data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total loans issued\n",
    "loan_data['loan_status'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loan proportion of each observation\n",
    "loan_data['loan_status'].value_counts() / loan_data['loan_status'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good/ Bad loan.# We create a new variable that has the value of '0' if a condition is met (Default), and the value of '1' if it is not met (Non-default). \n",
    "loan_data['good_bad'] = np.where(loan_data['loan_status'].isin(['Charged Off', 'Default',\n",
    "                                                       'Does not meet the credit policy. Status:Charged Off',\n",
    "                                                       'Late (31-120 days)']), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['good_bad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split two dataframes with inputs and targets, each into a train and test dataframe, and store them in variables.\n",
    "# We set the size of the test dataset to be 20% and the train dataset becomes 80%.\n",
    "# We also set a specific random state.This would allow us to perform the exact same split multimple times.\n",
    "# This means, to assign the exact same observations to the train and test datasets.\n",
    "loan_data_inputs_train, loan_data_inputs_test, loan_data_targets_train, loan_data_targets_test = train_test_split(loan_data.drop('good_bad', axis = 1), loan_data['good_bad'], test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the size of the dataframes\n",
    "print(loan_data_inputs_train.shape)\n",
    "print(loan_data_targets_train.shape)\n",
    "print(loan_data_inputs_test.shape)\n",
    "print(loan_data_targets_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING: TRAINING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing More Discrete/ Categorical Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Creating variables*\n",
    "1. `n_obs` is total number of observations\n",
    "2. `WOE` is Weight of Evidence\n",
    "3. `n_good` is number of good loans\n",
    "4. `n_bad` is number od bad loans\n",
    "5. `prop_good` is proportion of good borrowers\n",
    "6. `prop_bad` is proportion of bad borrowers\n",
    "7. `prop_n_obs` is proportion of observations\n",
    "8. `prop_n_good` is proportion of the number of good borrowers\n",
    "9. `prop_n_bad` is proportion of the nuber of bad borrowers\n",
    "10. `IV` is information value\n",
    "11. `diff_prop_good` is difference of the proportion of good borrowers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr = loan_data_inputs_train\n",
    "df_targets_prepr = loan_data_targets_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes 3 arguments: a dataframe, a string, and a dataframe. The function returns a dataframe as a result.\n",
    "# WoE function for discrete unordered variables\n",
    "def woe_discrete(df, discrete_variabe_name, good_bad_variable_df):\n",
    "    df = pd.concat([df[discrete_variabe_name], good_bad_variable_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    df = df.sort_values(['WoE'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade variable\n",
    "#Executing the function and storing it in a dataframe\n",
    "df_temp = woe_discrete(df_inputs_prepr, 'grade', df_targets_prepr)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Informaton Value(IV) falls within 0.3 and 0.5, indicating strong predictive power. That is, `0.3<IV<0.5` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the Preprocessed variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a function that takes 2 arguments: a dataframe and a number.\n",
    "def plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n",
    "    # Turns the values of the column with index 0 to strings, makes an array from these strings, and passes it to variable x.\n",
    "    x = np.array(df_WoE.iloc[:, 0].apply(str))\n",
    "    # Selects a column with label 'WoE' and passes it to variable y.\n",
    "    y = df_WoE['WoE']\n",
    "    \n",
    "    #Plotting the figure\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.plot(x, y, marker = 'o', linestyle = '--', color = 'k')\n",
    "    plt.xlabel(df_WoE.columns[0])\n",
    "    plt.ylabel('Weight of Evidence')\n",
    "    plt.title(str('Weight of Evidence by ' + df_WoE.columns[0]))\n",
    "    plt.xticks(rotation = rotation_of_x_axis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the grade, the greater the weight of evidence. That means loans with greater external ratings are greater on avaerage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Discrete Variables: Creating Dummy Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_ownership variable\n",
    "#Executing our previous WOE function\n",
    "df_temp1 = woe_discrete(df_inputs_prepr, 'home_ownership', df_targets_prepr)\n",
    "df_temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the weight of evidence (woe) values by excuting the plot function we created previously.\n",
    "plot_by_woe(df_temp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many categories with home_ownership variable.\n",
    "# Therefore, we create a new discrete variable where we combine some of the categories.\n",
    "# 'OTHER', 'ANY' and 'NONE' are riskiest but are very few. 'RENT' is the next riskiest.\n",
    "# We combine them in one category, 'RENT_OTHER_NONE_ANY'.\n",
    "# We end up with 3 categories for the 'home_onership': 'RENT_OTHER_NONE_ANY', 'OWN', 'MORTGAGE'.\n",
    "df_inputs_prepr['home_ownership:RENT_OTHER_NONE_ANY'] = sum([df_inputs_prepr['home_ownership:RENT'], df_inputs_prepr['home_ownership:OTHER'],\n",
    "                                                      df_inputs_prepr['home_ownership:NONE'],df_inputs_prepr['home_ownership:ANY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique caterogies in the addr_state variable\n",
    "df_inputs_prepr['addr_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addr_state variable\n",
    "# We calculate weight of evidence.\n",
    "df_temp2 = woe_discrete(df_inputs_prepr, 'addr_state', df_targets_prepr)\n",
    "df_temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to get a normal curve\n",
    "if ['addr_state:ND'] in df_inputs_prepr.columns.values:\n",
    "    pass\n",
    "else:\n",
    "    df_inputs_prepr['addr_state:ND'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values again for the 'addr_state' by removing the state IA and AL.\n",
    "plot_by_woe(df_temp2.iloc[2: -2, : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values again by removing the upper states OR, NH, DC, ID, VT, ME.\n",
    "plot_by_woe(df_temp2.iloc[6: -6, : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies for the 'addr_state' variable\n",
    "# We create the following categories:\n",
    "# 'ND' 'NE' 'IA' NV' 'FL' 'HI' 'AL'\n",
    "# 'NM' 'VA'\n",
    "# 'NY'\n",
    "# 'OK' 'TN' 'MO' 'LA' 'MD' 'NC'\n",
    "# 'CA'\n",
    "# 'UT' 'KY' 'AZ' 'NJ'\n",
    "# 'AR' 'MI' 'PA' 'OH' 'MN'\n",
    "# 'RI' 'MA' 'DE' 'SD' 'IN'\n",
    "# 'GA' 'WA' 'OR'\n",
    "# 'WI' 'MT'\n",
    "# 'TX'\n",
    "# 'IL' 'CT'\n",
    "# 'KS' 'SC' 'CO' 'VT' 'AK' 'MS'\n",
    "# 'WV' 'NH' 'WY' 'DC' 'ME' 'ID'\n",
    "\n",
    "# 'ND_NE_IA_NV_FL_HI_AL' will be the reference category.\n",
    "\n",
    "df_inputs_prepr['addr_state:ND_NE_IA_NV_FL_HI_AL'] = sum([df_inputs_prepr['addr_state:ND'], df_inputs_prepr['addr_state:NE'],\n",
    "                                              df_inputs_prepr['addr_state:IA'], df_inputs_prepr['addr_state:NV'],\n",
    "                                              df_inputs_prepr['addr_state:FL'], df_inputs_prepr['addr_state:HI'],\n",
    "                                                          df_inputs_prepr['addr_state:AL']])\n",
    "\n",
    "df_inputs_prepr['addr_state:NM_VA'] = sum([df_inputs_prepr['addr_state:NM'], df_inputs_prepr['addr_state:VA']])\n",
    "\n",
    "df_inputs_prepr['addr_state:OK_TN_MO_LA_MD_NC'] = sum([df_inputs_prepr['addr_state:OK'], df_inputs_prepr['addr_state:TN'],\n",
    "                                              df_inputs_prepr['addr_state:MO'], df_inputs_prepr['addr_state:LA'],\n",
    "                                              df_inputs_prepr['addr_state:MD'], df_inputs_prepr['addr_state:NC']])\n",
    "\n",
    "df_inputs_prepr['addr_state:UT_KY_AZ_NJ'] = sum([df_inputs_prepr['addr_state:UT'], df_inputs_prepr['addr_state:KY'],\n",
    "                                              df_inputs_prepr['addr_state:AZ'], df_inputs_prepr['addr_state:NJ']])\n",
    "\n",
    "df_inputs_prepr['addr_state:AR_MI_PA_OH_MN'] = sum([df_inputs_prepr['addr_state:AR'], df_inputs_prepr['addr_state:MI'],\n",
    "                                              df_inputs_prepr['addr_state:PA'], df_inputs_prepr['addr_state:OH'],\n",
    "                                              df_inputs_prepr['addr_state:MN']])\n",
    "\n",
    "df_inputs_prepr['addr_state:RI_MA_DE_SD_IN'] = sum([df_inputs_prepr['addr_state:RI'], df_inputs_prepr['addr_state:MA'],\n",
    "                                              df_inputs_prepr['addr_state:DE'], df_inputs_prepr['addr_state:SD'],\n",
    "                                              df_inputs_prepr['addr_state:IN']])\n",
    "\n",
    "df_inputs_prepr['addr_state:GA_WA_OR'] = sum([df_inputs_prepr['addr_state:GA'], df_inputs_prepr['addr_state:WA'],\n",
    "                                              df_inputs_prepr['addr_state:OR']])\n",
    "\n",
    "df_inputs_prepr['addr_state:WI_MT'] = sum([df_inputs_prepr['addr_state:WI'], df_inputs_prepr['addr_state:MT']])\n",
    "\n",
    "df_inputs_prepr['addr_state:IL_CT'] = sum([df_inputs_prepr['addr_state:IL'], df_inputs_prepr['addr_state:CT']])\n",
    "\n",
    "df_inputs_prepr['addr_state:KS_SC_CO_VT_AK_MS'] = sum([df_inputs_prepr['addr_state:KS'], df_inputs_prepr['addr_state:SC'],\n",
    "                                              df_inputs_prepr['addr_state:CO'], df_inputs_prepr['addr_state:VT'],\n",
    "                                              df_inputs_prepr['addr_state:AK'], df_inputs_prepr['addr_state:MS']])\n",
    "\n",
    "df_inputs_prepr['addr_state:WV_NH_WY_DC_ME_ID'] = sum([df_inputs_prepr['addr_state:WV'], df_inputs_prepr['addr_state:NH'],\n",
    "                                              df_inputs_prepr['addr_state:WY'], df_inputs_prepr['addr_state:DC'],\n",
    "                                              df_inputs_prepr['addr_state:ME'], df_inputs_prepr['addr_state:ID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'verification_status' variable'\n",
    "# We calculate weight of evidence.\n",
    "\n",
    "df_temp3 = woe_discrete(df_inputs_prepr, 'verification_status', df_targets_prepr)\n",
    "df_temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'purpose' variable\n",
    "# We calculate weight of evidence.\n",
    "\n",
    "df_temp4 = woe_discrete(df_inputs_prepr, 'purpose', df_targets_prepr)\n",
    "df_temp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df_temp4, 90)\n",
    "# We plot the weight of evidence values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create dummy variables for the 'purpose' variable\n",
    "# We combine 'educational', 'small_business', 'wedding', 'renewable_energy', 'moving', 'house' in one category: 'educ__sm_b__wedd__ren_en__mov__house'.\n",
    "# We combine 'other', 'medical', 'vacation' in one category: 'oth__med__vacation'.\n",
    "# We combine 'major_purchase', 'car', 'home_improvement' in one category: 'major_purch__car__home_impr'.\n",
    "# We leave 'debt_consolidtion' in a separate category.\n",
    "# We leave 'credit_card' in a separate category.\n",
    "# 'educ__sm_b__wedd__ren_en__mov__house' will be the reference category.\n",
    "df_inputs_prepr['purpose:educ__sm_b__wedd__ren_en__mov__house'] = sum([df_inputs_prepr['purpose:educational'], df_inputs_prepr['purpose:small_business'],\n",
    "                                                                 df_inputs_prepr['purpose:wedding'], df_inputs_prepr['purpose:renewable_energy'],\n",
    "                                                                 df_inputs_prepr['purpose:moving'], df_inputs_prepr['purpose:house']])\n",
    "df_inputs_prepr['purpose:oth__med__vacation'] = sum([df_inputs_prepr['purpose:other'], df_inputs_prepr['purpose:medical'],\n",
    "                                             df_inputs_prepr['purpose:vacation']])\n",
    "df_inputs_prepr['purpose:major_purch__car__home_impr'] = sum([df_inputs_prepr['purpose:major_purchase'], df_inputs_prepr['purpose:car'],\n",
    "                                                        df_inputs_prepr['purpose:home_improvement']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'initial_list_status' variable\n",
    "# We calculate weight of evidence.\n",
    "\n",
    "df_temp5 = woe_discrete(df_inputs_prepr, 'initial_list_status', df_targets_prepr)\n",
    "df_temp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Continuous Variables: Creating dummy variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WoE function for ordered discrete and continuous variables\n",
    "# The function takes 3 arguments: a dataframe, a string, and a dataframe. The function returns a dataframe as a result.\n",
    "\n",
    "def woe_ordered_continuous(df, discrete_variabe_name, good_bad_variable_df):\n",
    "    df = pd.concat([df[discrete_variabe_name], good_bad_variable_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    #df = df.sort_values(['WoE'])\n",
    "    #df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# term variable\n",
    "# There are only two unique values, 36 and 60.\n",
    "df_inputs_prepr['term_int'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp6 = woe_ordered_continuous(df_inputs_prepr, 'term_int', df_targets_prepr)\n",
    "df_temp6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems 60 months loans are much risky than 36 months loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will keep both the 36 and 60 months category.\n",
    "# However the '60' months will be the reference category.\n",
    "df_inputs_prepr['term:36'] = np.where((df_inputs_prepr['term_int'] == 36), 1, 0)\n",
    "df_inputs_prepr['term:60'] = np.where((df_inputs_prepr['term_int'] == 60), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_length_int variable\n",
    "# Has only 11 levels: from 0 to 10. Hence, we turn it into a factor with 11 levels.\n",
    "df_inputs_prepr['emp_length_int'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp7 = woe_ordered_continuous(df_inputs_prepr, 'emp_length_int', df_targets_prepr)\n",
    "df_temp7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment length has several categories\n",
    "# So we have to create the following new categories for emp_length_int: '0', '1', '2 - 4', '5 - 6', '7 - 9', '10'\n",
    "# '0' will be the reference category\n",
    "df_inputs_prepr['emp_length:0'] = np.where(df_inputs_prepr['emp_length_int'].isin([0]), 1, 0)\n",
    "df_inputs_prepr['emp_length:1'] = np.where(df_inputs_prepr['emp_length_int'].isin([1]), 1, 0)\n",
    "df_inputs_prepr['emp_length:2-4'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(2, 5)), 1, 0)\n",
    "df_inputs_prepr['emp_length:5-6'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(5, 7)), 1, 0)\n",
    "df_inputs_prepr['emp_length:7-9'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(7, 10)), 1, 0)\n",
    "df_inputs_prepr['emp_length:10'] = np.where(df_inputs_prepr['emp_length_int'].isin([10]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months since loan issue date (mths_since_issue_d) variable\n",
    "df_inputs_prepr['mths_since_issue_d'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['mths_since_issue_d_factor'] = pd.cut(df_inputs_prepr['mths_since_issue_d'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr['mths_since_issue_d_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_issue_d\n",
    "# We calculate weight of evidence.\n",
    "df_temp8 = woe_ordered_continuous(df_inputs_prepr, 'mths_since_issue_d_factor', df_targets_prepr)\n",
    "df_temp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to rotate the labels because we cannot read them otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values, rotating the labels 90 degrees.\n",
    "plot_by_woe(df_temp8, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp8.iloc[3: , : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# < 38, 38 - 39, 40 - 41, 42 - 48, 49 - 52, 53 - 64, 65 - 84, > 84.\n",
    "df_inputs_prepr['mths_since_issue_d:<38'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(38)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:38-39'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(38, 40)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:40-41'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(40, 42)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:42-48'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(42, 49)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:49-52'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(49, 53)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:53-64'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(53, 65)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:65-84'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(65, 85)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:>84'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(85, int(df_inputs_prepr['mths_since_issue_d'].max()))), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_rate variable\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['int_rate_factor'] = pd.cut(df_inputs_prepr['int_rate'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp9 = woe_ordered_continuous(df_inputs_prepr, 'int_rate_factor', df_targets_prepr)\n",
    "df_temp9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp9, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# '< 9.548', '9.548 - 12.025', '12.025 - 15.74', '15.74 - 20.281', '> 20.281'\n",
    "df_inputs_prepr['int_rate:<9.548'] = np.where((df_inputs_prepr['int_rate'] <= 9.548), 1, 0)\n",
    "df_inputs_prepr['int_rate:9.548-12.025'] = np.where((df_inputs_prepr['int_rate'] > 9.548) & (df_inputs_prepr['int_rate'] <= 12.025), 1, 0)\n",
    "df_inputs_prepr['int_rate:12.025-15.74'] = np.where((df_inputs_prepr['int_rate'] > 12.025) & (df_inputs_prepr['int_rate'] <= 15.74), 1, 0)\n",
    "df_inputs_prepr['int_rate:15.74-20.281'] = np.where((df_inputs_prepr['int_rate'] > 15.74) & (df_inputs_prepr['int_rate'] <= 20.281), 1, 0)\n",
    "df_inputs_prepr['int_rate:>20.281'] = np.where((df_inputs_prepr['int_rate'] > 20.281), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funded_amnt variable\n",
    "df_inputs_prepr['funded_amnt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['funded_amnt_factor'] = pd.cut(df_inputs_prepr['funded_amnt'], 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp10 = woe_ordered_continuous(df_inputs_prepr, 'funded_amnt_factor', df_targets_prepr)\n",
    "df_temp10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp10, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_earliest_cr_line variable\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['mths_since_earliest_cr_line_factor'] = pd.cut(df_inputs_prepr['mths_since_earliest_cr_line'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp11 = woe_ordered_continuous(df_inputs_prepr, 'mths_since_earliest_cr_line_factor', df_targets_prepr)\n",
    "df_temp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp11, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp11.iloc[6: , : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# < 140, # 141 - 164, # 165 - 247, # 248 - 270, # 271 - 352, # > 352\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:<140'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(140)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:141-164'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(140, 165)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:165-247'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(165, 248)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:248-270'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(248, 271)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:271-352'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(271, 353)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:>352'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(353, int(df_inputs_prepr['mths_since_earliest_cr_line'].max()))), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delinq_2yrs variable\n",
    "# We calculate weight of evidence\n",
    "df_temp12 = woe_ordered_continuous(df_inputs_prepr, 'delinq_2yrs', df_targets_prepr)\n",
    "df_temp12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: 0, 1-3, >=4\n",
    "df_inputs_prepr['delinq_2yrs:0'] = np.where((df_inputs_prepr['delinq_2yrs'] == 0), 1, 0)\n",
    "df_inputs_prepr['delinq_2yrs:1-3'] = np.where((df_inputs_prepr['delinq_2yrs'] >= 1) & (df_inputs_prepr['delinq_2yrs'] <= 3), 1, 0)\n",
    "df_inputs_prepr['delinq_2yrs:>=4'] = np.where((df_inputs_prepr['delinq_2yrs'] >= 9), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inq_last_6mths variable\n",
    "# We calculate weight of evidence.\n",
    "df_temp13 = woe_ordered_continuous(df_inputs_prepr, 'inq_last_6mths', df_targets_prepr)\n",
    "df_temp13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: 0, 1 - 2, 3 - 6, > 6\n",
    "df_inputs_prepr['inq_last_6mths:0'] = np.where((df_inputs_prepr['inq_last_6mths'] == 0), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:1-2'] = np.where((df_inputs_prepr['inq_last_6mths'] >= 1) & (df_inputs_prepr['inq_last_6mths'] <= 2), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:3-6'] = np.where((df_inputs_prepr['inq_last_6mths'] >= 3) & (df_inputs_prepr['inq_last_6mths'] <= 6), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:>6'] = np.where((df_inputs_prepr['inq_last_6mths'] > 6), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_acc variable\n",
    "# We calculate weight of evidence.\n",
    "df_temp14 = woe_ordered_continuous(df_inputs_prepr, 'open_acc', df_targets_prepr)\n",
    "df_temp14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp14, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp14.iloc[ : 40, :], 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: '0', '1-3', '4-12', '13-17', '18-22', '23-25', '26-30', '>30'\n",
    "df_inputs_prepr['open_acc:0'] = np.where((df_inputs_prepr['open_acc'] == 0), 1, 0)\n",
    "df_inputs_prepr['open_acc:1-3'] = np.where((df_inputs_prepr['open_acc'] >= 1) & (df_inputs_prepr['open_acc'] <= 3), 1, 0)\n",
    "df_inputs_prepr['open_acc:4-12'] = np.where((df_inputs_prepr['open_acc'] >= 4) & (df_inputs_prepr['open_acc'] <= 12), 1, 0)\n",
    "df_inputs_prepr['open_acc:13-17'] = np.where((df_inputs_prepr['open_acc'] >= 13) & (df_inputs_prepr['open_acc'] <= 17), 1, 0)\n",
    "df_inputs_prepr['open_acc:18-22'] = np.where((df_inputs_prepr['open_acc'] >= 18) & (df_inputs_prepr['open_acc'] <= 22), 1, 0)\n",
    "df_inputs_prepr['open_acc:23-25'] = np.where((df_inputs_prepr['open_acc'] >= 23) & (df_inputs_prepr['open_acc'] <= 25), 1, 0)\n",
    "df_inputs_prepr['open_acc:26-30'] = np.where((df_inputs_prepr['open_acc'] >= 26) & (df_inputs_prepr['open_acc'] <= 30), 1, 0)\n",
    "df_inputs_prepr['open_acc:>=31'] = np.where((df_inputs_prepr['open_acc'] >= 31), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_rec variable\n",
    "# We calculate weight of evidence\n",
    "df_temp15 = woe_ordered_continuous(df_inputs_prepr, 'pub_rec', df_targets_prepr)\n",
    "df_temp15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp15, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: '0-2', '3-4', '>=5'\n",
    "df_inputs_prepr['pub_rec:0-2'] = np.where((df_inputs_prepr['pub_rec'] >= 0) & (df_inputs_prepr['pub_rec'] <= 2), 1, 0)\n",
    "df_inputs_prepr['pub_rec:3-4'] = np.where((df_inputs_prepr['pub_rec'] >= 3) & (df_inputs_prepr['pub_rec'] <= 4), 1, 0)\n",
    "df_inputs_prepr['pub_rec:>=5'] = np.where((df_inputs_prepr['pub_rec'] >= 5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_acc variable\n",
    "df_inputs_prepr['total_acc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['total_acc_factor'] = pd.cut(df_inputs_prepr['total_acc'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence\n",
    "df_temp16 = woe_ordered_continuous(df_inputs_prepr, 'total_acc_factor', df_targets_prepr)\n",
    "df_temp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp16, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: '<=27', '28-51', '>51'\n",
    "df_inputs_prepr['total_acc:<=27'] = np.where((df_inputs_prepr['total_acc'] <= 27), 1, 0)\n",
    "df_inputs_prepr['total_acc:28-51'] = np.where((df_inputs_prepr['total_acc'] >= 28) & (df_inputs_prepr['total_acc'] <= 51), 1, 0)\n",
    "df_inputs_prepr['total_acc:>=52'] = np.where((df_inputs_prepr['total_acc'] >= 52), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_now_delinq variable\n",
    "# We calculate weight of evidence.\n",
    "df_temp17 = woe_ordered_continuous(df_inputs_prepr, 'acc_now_delinq', df_targets_prepr)\n",
    "df_temp17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: '0', '>=1'\n",
    "df_inputs_prepr['acc_now_delinq:0'] = np.where((df_inputs_prepr['acc_now_delinq'] == 0), 1, 0)\n",
    "df_inputs_prepr['acc_now_delinq:>=1'] = np.where((df_inputs_prepr['acc_now_delinq'] >= 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rev_hi_lim variable\n",
    "df_inputs_prepr['total_rev_hi_lim'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 2000 categories by its values.\n",
    "df_inputs_prepr['total_rev_hi_lim_factor'] = pd.cut(df_inputs_prepr['total_rev_hi_lim'], 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp18 = woe_ordered_continuous(df_inputs_prepr, 'total_rev_hi_lim_factor', df_targets_prepr)\n",
    "df_temp18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp18.iloc[: 50, : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories:'<=5K', '5K-10K', '10K-20K', '20K-30K', '30K-40K', '40K-55K', '55K-95K', '>95K'\n",
    "df_inputs_prepr['total_rev_hi_lim:<=5K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] <= 5000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:5K-10K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 5000) & (df_inputs_prepr['total_rev_hi_lim'] <= 10000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:10K-20K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 10000) & (df_inputs_prepr['total_rev_hi_lim'] <= 20000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:20K-30K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 20000) & (df_inputs_prepr['total_rev_hi_lim'] <= 30000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:30K-40K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 30000) & (df_inputs_prepr['total_rev_hi_lim'] <= 40000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:40K-55K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 40000) & (df_inputs_prepr['total_rev_hi_lim'] <= 55000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:55K-95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 55000) & (df_inputs_prepr['total_rev_hi_lim'] <= 95000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:>95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 95000), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installment variable\n",
    "df_inputs_prepr['installment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['installment_factor'] = pd.cut(df_inputs_prepr['installment'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp19 = woe_ordered_continuous(df_inputs_prepr, 'installment_factor', df_targets_prepr)\n",
    "df_temp19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp19, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual_inc variable\n",
    "df_inputs_prepr['annual_inc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['annual_inc_factor'] = pd.cut(df_inputs_prepr['annual_inc'], 50)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp20 = woe_ordered_continuous(df_inputs_prepr, 'annual_inc_factor', df_targets_prepr)\n",
    "df_temp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the initial ‘annual income’ variable into 50 categories doesn't work well for fine classing because there are a lot of people with low income and very few people with high income.\n",
    "# Thus, we do fine-classing using the 'cut' method, we split the variable into 100 categories by its values.\n",
    "df_inputs_prepr['annual_inc_factor'] = pd.cut(df_inputs_prepr['annual_inc'], 100)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp20 = woe_ordered_continuous(df_inputs_prepr, 'annual_inc_factor', df_targets_prepr)\n",
    "df_temp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial examination shows that there are too few individuals with large income and too many with small income.\n",
    "# Hence, we are going to have one category for more than 150K, and we are going to apply our approach to determine\n",
    "# the categories of everyone with 140k or less.\n",
    "df_inputs_prepr_temp = df_inputs_prepr.loc[df_inputs_prepr['annual_inc'] <= 140000, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr_temp[\"annual_inc_factor\"] = pd.cut(df_inputs_prepr_temp['annual_inc'], 50)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp20 = woe_ordered_continuous(df_inputs_prepr_temp, 'annual_inc_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
    "df_temp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp20, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WoE is monotonically decreasing with income, so we split income in 10 equal categories, each with width of 15k.\n",
    "df_inputs_prepr['annual_inc:<20K'] = np.where((df_inputs_prepr['annual_inc'] <= 20000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:20K-30K'] = np.where((df_inputs_prepr['annual_inc'] > 20000) & (df_inputs_prepr['annual_inc'] <= 30000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:30K-40K'] = np.where((df_inputs_prepr['annual_inc'] > 30000) & (df_inputs_prepr['annual_inc'] <= 40000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:40K-50K'] = np.where((df_inputs_prepr['annual_inc'] > 40000) & (df_inputs_prepr['annual_inc'] <= 50000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:50K-60K'] = np.where((df_inputs_prepr['annual_inc'] > 50000) & (df_inputs_prepr['annual_inc'] <= 60000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:60K-70K'] = np.where((df_inputs_prepr['annual_inc'] > 60000) & (df_inputs_prepr['annual_inc'] <= 70000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:70K-80K'] = np.where((df_inputs_prepr['annual_inc'] > 70000) & (df_inputs_prepr['annual_inc'] <= 80000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:80K-90K'] = np.where((df_inputs_prepr['annual_inc'] > 80000) & (df_inputs_prepr['annual_inc'] <= 90000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:90K-100K'] = np.where((df_inputs_prepr['annual_inc'] > 90000) & (df_inputs_prepr['annual_inc'] <= 100000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:100K-120K'] = np.where((df_inputs_prepr['annual_inc'] > 100000) & (df_inputs_prepr['annual_inc'] <= 120000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:120K-140K'] = np.where((df_inputs_prepr['annual_inc'] > 120000) & (df_inputs_prepr['annual_inc'] <= 140000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:>140K'] = np.where((df_inputs_prepr['annual_inc'] > 140000), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_delinq variable\n",
    "# We have to create one category for missing values and do fine and coarse classing for the rest.\n",
    "df_inputs_prepr_temp = df_inputs_prepr[pd.notnull(df_inputs_prepr['mths_since_last_delinq'])]\n",
    "df_inputs_prepr_temp['mths_since_last_delinq_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_delinq'], 50)\n",
    "\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp21 = woe_ordered_continuous(df_inputs_prepr_temp, 'mths_since_last_delinq_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
    "df_temp21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp21, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: Missing, 0-3, 4-30, 31-56, >=57\n",
    "df_inputs_prepr['mths_since_last_delinq:Missing'] = np.where((df_inputs_prepr['mths_since_last_delinq'].isnull()), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:0-3'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 0) & (df_inputs_prepr['mths_since_last_delinq'] <= 3), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:4-30'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 4) & (df_inputs_prepr['mths_since_last_delinq'] <= 30), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:31-56'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 31) & (df_inputs_prepr['mths_since_last_delinq'] <= 56), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:>=57'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 57), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dti variable\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 100 categories by its values.\n",
    "df_inputs_prepr['dti_factor'] = pd.cut(df_inputs_prepr['dti'], 100)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp22 = woe_ordered_continuous(df_inputs_prepr, 'dti_factor', df_targets_prepr)\n",
    "df_temp22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp22, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly to income, initial examination shows that most values are lower than 200.\n",
    "# Hence, we are going to have one category for more than 35, and we are going to apply our approach to determine\n",
    "# the categories of everyone with 150k or less.\n",
    "df_inputs_prepr_temp = df_inputs_prepr.loc[df_inputs_prepr['dti'] <= 35, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr_temp['dti_factor'] = pd.cut(df_inputs_prepr_temp['dti'], 50)\n",
    "\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp22 = woe_ordered_continuous(df_inputs_prepr_temp, 'dti_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
    "df_temp22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp22, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories:\n",
    "df_inputs_prepr['dti:<=1.4'] = np.where((df_inputs_prepr['dti'] <= 1.4), 1, 0)\n",
    "df_inputs_prepr['dti:1.4-3.5'] = np.where((df_inputs_prepr['dti'] > 1.4) & (df_inputs_prepr['dti'] <= 3.5), 1, 0)\n",
    "df_inputs_prepr['dti:3.5-7.7'] = np.where((df_inputs_prepr['dti'] > 3.5) & (df_inputs_prepr['dti'] <= 7.7), 1, 0)\n",
    "df_inputs_prepr['dti:7.7-10.5'] = np.where((df_inputs_prepr['dti'] > 7.7) & (df_inputs_prepr['dti'] <= 10.5), 1, 0)\n",
    "df_inputs_prepr['dti:10.5-16.1'] = np.where((df_inputs_prepr['dti'] > 10.5) & (df_inputs_prepr['dti'] <= 16.1), 1, 0)\n",
    "df_inputs_prepr['dti:16.1-20.3'] = np.where((df_inputs_prepr['dti'] > 16.1) & (df_inputs_prepr['dti'] <= 20.3), 1, 0)\n",
    "df_inputs_prepr['dti:20.3-21.7'] = np.where((df_inputs_prepr['dti'] > 20.3) & (df_inputs_prepr['dti'] <= 21.7), 1, 0)\n",
    "df_inputs_prepr['dti:21.7-22.4'] = np.where((df_inputs_prepr['dti'] > 21.7) & (df_inputs_prepr['dti'] <= 22.4), 1, 0)\n",
    "df_inputs_prepr['dti:22.4-35'] = np.where((df_inputs_prepr['dti'] > 22.4) & (df_inputs_prepr['dti'] <= 35), 1, 0)\n",
    "df_inputs_prepr['dti:>35'] = np.where((df_inputs_prepr['dti'] > 35), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_record variable\n",
    "# We have to create one category for missing values and do fine and coarse classing for the rest.\n",
    "#sum(loan_data_temp['mths_since_last_record'].isnull())\n",
    "\n",
    "df_inputs_prepr_temp = df_inputs_prepr[pd.notnull(df_inputs_prepr['mths_since_last_record'])]\n",
    "\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr_temp['mths_since_last_record_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_record'], 50)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp23 = woe_ordered_continuous(df_inputs_prepr_temp, 'mths_since_last_record_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
    "df_temp23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp23, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: 'Missing', '0-2', '3-20', '21-31', '32-80', '81-86', '>86'\n",
    "df_inputs_prepr['mths_since_last_record:Missing'] = np.where((df_inputs_prepr['mths_since_last_record'].isnull()), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:0-2'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 0) & (df_inputs_prepr['mths_since_last_record'] <= 2), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:3-20'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 3) & (df_inputs_prepr['mths_since_last_record'] <= 20), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:21-31'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 21) & (df_inputs_prepr['mths_since_last_record'] <= 31), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:32-80'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 32) & (df_inputs_prepr['mths_since_last_record'] <= 80), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:81-86'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 81) & (df_inputs_prepr['mths_since_last_record'] <= 86), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:>86'] = np.where((df_inputs_prepr['mths_since_last_record'] > 86), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING: TEST DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will do the same like we did for the train dataset above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr = loan_data_inputs_test\n",
    "df_targets_prepr = loan_data_targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes 3 arguments: a dataframe, a string, and a dataframe. The function returns a dataframe as a result.\n",
    "# WoE function for discrete unordered variables\n",
    "def woe_discrete(df, discrete_variabe_name, good_bad_variable_df):\n",
    "    df = pd.concat([df[discrete_variabe_name], good_bad_variable_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    df = df.sort_values(['WoE'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade variable\n",
    "#Executing the function and storing it in a dataframe\n",
    "df_temp = woe_discrete(df_inputs_prepr, 'grade', df_targets_prepr)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a function that takes 2 arguments: a dataframe and a number.\n",
    "def plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n",
    "    # Turns the values of the column with index 0 to strings, makes an array from these strings, and passes it to variable x.\n",
    "    x = np.array(df_WoE.iloc[:, 0].apply(str))\n",
    "    # Selects a column with label 'WoE' and passes it to variable y.\n",
    "    y = df_WoE['WoE']\n",
    "    \n",
    "    #Plotting the figure\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.plot(x, y, marker = 'o', linestyle = '--', color = 'k')\n",
    "    plt.xlabel(df_WoE.columns[0])\n",
    "    plt.ylabel('Weight of Evidence')\n",
    "    plt.title(str('Weight of Evidence by ' + df_WoE.columns[0]))\n",
    "    plt.xticks(rotation = rotation_of_x_axis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the grade, the greater the weight of evidence. That means loans with greater external ratings are greater on avaerage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_ownership variable\n",
    "#Executing our previous WOE function\n",
    "df_temp1 = woe_discrete(df_inputs_prepr, 'home_ownership', df_targets_prepr)\n",
    "df_temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the weight of evidence (woe) values by excuting the plot function we created previously.\n",
    "plot_by_woe(df_temp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many categories with home_ownership variable.\n",
    "# Therefore, we create a new discrete variable where we combine some of the categories.\n",
    "# 'OTHER', 'ANY' and 'NONE' are riskiest but are very few. 'RENT' is the next riskiest.\n",
    "# We combine them in one category, 'RENT_OTHER_NONE_ANY'.\n",
    "# We end up with 3 categories for the 'home_onership': 'RENT_OTHER_NONE_ANY', 'OWN', 'MORTGAGE'.\n",
    "df_inputs_prepr['home_ownership:RENT_OTHER_NONE_ANY'] = sum([df_inputs_prepr['home_ownership:RENT'], df_inputs_prepr['home_ownership:OTHER'],\n",
    "                                                      df_inputs_prepr['home_ownership:NONE'],df_inputs_prepr['home_ownership:ANY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique caterogies in the addr_state variable\n",
    "df_inputs_prepr['addr_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addr_state variable\n",
    "# We calculate weight of evidence.\n",
    "df_temp2 = woe_discrete(df_inputs_prepr, 'addr_state', df_targets_prepr)\n",
    "df_temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to get a normal curve\n",
    "if ['addr_state:ND'] in df_inputs_prepr.columns.values:\n",
    "    pass\n",
    "else:\n",
    "    df_inputs_prepr['addr_state:ND'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values again for the 'addr_state' by removing the state IA and AL.\n",
    "plot_by_woe(df_temp2.iloc[2: -2, : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values again by removing the upper states OR, NH, DC, ID, VT, ME.\n",
    "plot_by_woe(df_temp2.iloc[6: -6, : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies for the 'addr_state' variable\n",
    "# We create the following categories:\n",
    "# 'ND' 'NE' 'IA' NV' 'FL' 'HI' 'AL'\n",
    "# 'NM' 'VA'\n",
    "# 'NY'\n",
    "# 'OK' 'TN' 'MO' 'LA' 'MD' 'NC'\n",
    "# 'CA'\n",
    "# 'UT' 'KY' 'AZ' 'NJ'\n",
    "# 'AR' 'MI' 'PA' 'OH' 'MN'\n",
    "# 'RI' 'MA' 'DE' 'SD' 'IN'\n",
    "# 'GA' 'WA' 'OR'\n",
    "# 'WI' 'MT'\n",
    "# 'TX'\n",
    "# 'IL' 'CT'\n",
    "# 'KS' 'SC' 'CO' 'VT' 'AK' 'MS'\n",
    "# 'WV' 'NH' 'WY' 'DC' 'ME' 'ID'\n",
    "\n",
    "# 'ND_NE_IA_NV_FL_HI_AL' will be the reference category.\n",
    "\n",
    "df_inputs_prepr['addr_state:ND_NE_IA_NV_FL_HI_AL'] = sum([df_inputs_prepr['addr_state:ND'], df_inputs_prepr['addr_state:NE'],\n",
    "                                              df_inputs_prepr['addr_state:IA'], df_inputs_prepr['addr_state:NV'],\n",
    "                                              df_inputs_prepr['addr_state:FL'], df_inputs_prepr['addr_state:HI'],\n",
    "                                                          df_inputs_prepr['addr_state:AL']])\n",
    "\n",
    "df_inputs_prepr['addr_state:NM_VA'] = sum([df_inputs_prepr['addr_state:NM'], df_inputs_prepr['addr_state:VA']])\n",
    "\n",
    "df_inputs_prepr['addr_state:OK_TN_MO_LA_MD_NC'] = sum([df_inputs_prepr['addr_state:OK'], df_inputs_prepr['addr_state:TN'],\n",
    "                                              df_inputs_prepr['addr_state:MO'], df_inputs_prepr['addr_state:LA'],\n",
    "                                              df_inputs_prepr['addr_state:MD'], df_inputs_prepr['addr_state:NC']])\n",
    "\n",
    "df_inputs_prepr['addr_state:UT_KY_AZ_NJ'] = sum([df_inputs_prepr['addr_state:UT'], df_inputs_prepr['addr_state:KY'],\n",
    "                                              df_inputs_prepr['addr_state:AZ'], df_inputs_prepr['addr_state:NJ']])\n",
    "\n",
    "df_inputs_prepr['addr_state:AR_MI_PA_OH_MN'] = sum([df_inputs_prepr['addr_state:AR'], df_inputs_prepr['addr_state:MI'],\n",
    "                                              df_inputs_prepr['addr_state:PA'], df_inputs_prepr['addr_state:OH'],\n",
    "                                              df_inputs_prepr['addr_state:MN']])\n",
    "\n",
    "df_inputs_prepr['addr_state:RI_MA_DE_SD_IN'] = sum([df_inputs_prepr['addr_state:RI'], df_inputs_prepr['addr_state:MA'],\n",
    "                                              df_inputs_prepr['addr_state:DE'], df_inputs_prepr['addr_state:SD'],\n",
    "                                              df_inputs_prepr['addr_state:IN']])\n",
    "\n",
    "df_inputs_prepr['addr_state:GA_WA_OR'] = sum([df_inputs_prepr['addr_state:GA'], df_inputs_prepr['addr_state:WA'],\n",
    "                                              df_inputs_prepr['addr_state:OR']])\n",
    "\n",
    "df_inputs_prepr['addr_state:WI_MT'] = sum([df_inputs_prepr['addr_state:WI'], df_inputs_prepr['addr_state:MT']])\n",
    "\n",
    "df_inputs_prepr['addr_state:IL_CT'] = sum([df_inputs_prepr['addr_state:IL'], df_inputs_prepr['addr_state:CT']])\n",
    "\n",
    "df_inputs_prepr['addr_state:KS_SC_CO_VT_AK_MS'] = sum([df_inputs_prepr['addr_state:KS'], df_inputs_prepr['addr_state:SC'],\n",
    "                                              df_inputs_prepr['addr_state:CO'], df_inputs_prepr['addr_state:VT'],\n",
    "                                              df_inputs_prepr['addr_state:AK'], df_inputs_prepr['addr_state:MS']])\n",
    "\n",
    "df_inputs_prepr['addr_state:WV_NH_WY_DC_ME_ID'] = sum([df_inputs_prepr['addr_state:WV'], df_inputs_prepr['addr_state:NH'],\n",
    "                                              df_inputs_prepr['addr_state:WY'], df_inputs_prepr['addr_state:DC'],\n",
    "                                              df_inputs_prepr['addr_state:ME'], df_inputs_prepr['addr_state:ID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'verification_status' variable'\n",
    "# We calculate weight of evidence.\n",
    "\n",
    "df_temp3 = woe_discrete(df_inputs_prepr, 'verification_status', df_targets_prepr)\n",
    "df_temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'purpose' variable\n",
    "# We calculate weight of evidence.\n",
    "\n",
    "df_temp4 = woe_discrete(df_inputs_prepr, 'purpose', df_targets_prepr)\n",
    "df_temp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_woe(df_temp4, 90)\n",
    "# We plot the weight of evidence values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create dummy variables for the 'purpose' variable\n",
    "# We combine 'educational', 'small_business', 'wedding', 'renewable_energy', 'moving', 'house' in one category: 'educ__sm_b__wedd__ren_en__mov__house'.\n",
    "# We combine 'other', 'medical', 'vacation' in one category: 'oth__med__vacation'.\n",
    "# We combine 'major_purchase', 'car', 'home_improvement' in one category: 'major_purch__car__home_impr'.\n",
    "# We leave 'debt_consolidtion' in a separate category.\n",
    "# We leave 'credit_card' in a separate category.\n",
    "# 'educ__sm_b__wedd__ren_en__mov__house' will be the reference category.\n",
    "df_inputs_prepr['purpose:educ__sm_b__wedd__ren_en__mov__house'] = sum([df_inputs_prepr['purpose:educational'], df_inputs_prepr['purpose:small_business'],\n",
    "                                                                 df_inputs_prepr['purpose:wedding'], df_inputs_prepr['purpose:renewable_energy'],\n",
    "                                                                 df_inputs_prepr['purpose:moving'], df_inputs_prepr['purpose:house']])\n",
    "df_inputs_prepr['purpose:oth__med__vacation'] = sum([df_inputs_prepr['purpose:other'], df_inputs_prepr['purpose:medical'],\n",
    "                                             df_inputs_prepr['purpose:vacation']])\n",
    "df_inputs_prepr['purpose:major_purch__car__home_impr'] = sum([df_inputs_prepr['purpose:major_purchase'], df_inputs_prepr['purpose:car'],\n",
    "                                                        df_inputs_prepr['purpose:home_improvement']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'initial_list_status' variable\n",
    "# We calculate weight of evidence.\n",
    "\n",
    "df_temp5 = woe_discrete(df_inputs_prepr, 'initial_list_status', df_targets_prepr)\n",
    "df_temp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WoE function for ordered discrete and continuous variables\n",
    "# The function takes 3 arguments: a dataframe, a string, and a dataframe. The function returns a dataframe as a result.\n",
    "\n",
    "def woe_ordered_continuous(df, discrete_variabe_name, good_bad_variable_df):\n",
    "    df = pd.concat([df[discrete_variabe_name], good_bad_variable_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    #df = df.sort_values(['WoE'])\n",
    "    #df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# term variable\n",
    "# There are only two unique values, 36 and 60.\n",
    "df_inputs_prepr['term_int'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp6 = woe_ordered_continuous(df_inputs_prepr, 'term_int', df_targets_prepr)\n",
    "df_temp6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems 60 months loans are much risky than 36 months loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will keep both the 36 and 60 months category.\n",
    "# However the '60' months will be the reference category.\n",
    "df_inputs_prepr['term:36'] = np.where((df_inputs_prepr['term_int'] == 36), 1, 0)\n",
    "df_inputs_prepr['term:60'] = np.where((df_inputs_prepr['term_int'] == 60), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_length_int variable\n",
    "# Has only 11 levels: from 0 to 10. Hence, we turn it into a factor with 11 levels.\n",
    "df_inputs_prepr['emp_length_int'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp7 = woe_ordered_continuous(df_inputs_prepr, 'emp_length_int', df_targets_prepr)\n",
    "df_temp7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment length has several categories\n",
    "# So we have to create the following new categories for emp_length_int: '0', '1', '2 - 4', '5 - 6', '7 - 9', '10'\n",
    "# '0' will be the reference category\n",
    "df_inputs_prepr['emp_length:0'] = np.where(df_inputs_prepr['emp_length_int'].isin([0]), 1, 0)\n",
    "df_inputs_prepr['emp_length:1'] = np.where(df_inputs_prepr['emp_length_int'].isin([1]), 1, 0)\n",
    "df_inputs_prepr['emp_length:2-4'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(2, 5)), 1, 0)\n",
    "df_inputs_prepr['emp_length:5-6'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(5, 7)), 1, 0)\n",
    "df_inputs_prepr['emp_length:7-9'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(7, 10)), 1, 0)\n",
    "df_inputs_prepr['emp_length:10'] = np.where(df_inputs_prepr['emp_length_int'].isin([10]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months since loan issue date (mths_since_issue_d) variable\n",
    "df_inputs_prepr['mths_since_issue_d'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['mths_since_issue_d_factor'] = pd.cut(df_inputs_prepr['mths_since_issue_d'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr['mths_since_issue_d_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_issue_d\n",
    "# We calculate weight of evidence.\n",
    "df_temp8 = woe_ordered_continuous(df_inputs_prepr, 'mths_since_issue_d_factor', df_targets_prepr)\n",
    "df_temp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to rotate the labels because we cannot read them otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values, rotating the labels 90 degrees.\n",
    "plot_by_woe(df_temp8, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp8.iloc[3: , : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# < 38, 38 - 39, 40 - 41, 42 - 48, 49 - 52, 53 - 64, 65 - 84, > 84.\n",
    "df_inputs_prepr['mths_since_issue_d:<38'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(38)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:38-39'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(38, 40)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:40-41'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(40, 42)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:42-48'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(42, 49)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:49-52'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(49, 53)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:53-64'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(53, 65)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:65-84'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(65, 85)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:>84'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(85, int(df_inputs_prepr['mths_since_issue_d'].max()))), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_rate variable\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['int_rate_factor'] = pd.cut(df_inputs_prepr['int_rate'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp9 = woe_ordered_continuous(df_inputs_prepr, 'int_rate_factor', df_targets_prepr)\n",
    "df_temp9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp9, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# '< 9.548', '9.548 - 12.025', '12.025 - 15.74', '15.74 - 20.281', '> 20.281'\n",
    "df_inputs_prepr['int_rate:<9.548'] = np.where((df_inputs_prepr['int_rate'] <= 9.548), 1, 0)\n",
    "df_inputs_prepr['int_rate:9.548-12.025'] = np.where((df_inputs_prepr['int_rate'] > 9.548) & (df_inputs_prepr['int_rate'] <= 12.025), 1, 0)\n",
    "df_inputs_prepr['int_rate:12.025-15.74'] = np.where((df_inputs_prepr['int_rate'] > 12.025) & (df_inputs_prepr['int_rate'] <= 15.74), 1, 0)\n",
    "df_inputs_prepr['int_rate:15.74-20.281'] = np.where((df_inputs_prepr['int_rate'] > 15.74) & (df_inputs_prepr['int_rate'] <= 20.281), 1, 0)\n",
    "df_inputs_prepr['int_rate:>20.281'] = np.where((df_inputs_prepr['int_rate'] > 20.281), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funded_amnt variable\n",
    "df_inputs_prepr['funded_amnt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['funded_amnt_factor'] = pd.cut(df_inputs_prepr['funded_amnt'], 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp10 = woe_ordered_continuous(df_inputs_prepr, 'funded_amnt_factor', df_targets_prepr)\n",
    "df_temp10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp10, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_earliest_cr_line variable\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['mths_since_earliest_cr_line_factor'] = pd.cut(df_inputs_prepr['mths_since_earliest_cr_line'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp11 = woe_ordered_continuous(df_inputs_prepr, 'mths_since_earliest_cr_line_factor', df_targets_prepr)\n",
    "df_temp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp11, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp11.iloc[6: , : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# < 140, # 141 - 164, # 165 - 247, # 248 - 270, # 271 - 352, # > 352\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:<140'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(140)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:141-164'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(140, 165)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:165-247'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(165, 248)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:248-270'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(248, 271)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:271-352'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(271, 353)), 1, 0)\n",
    "df_inputs_prepr['mths_since_earliest_cr_line:>352'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(353, int(df_inputs_prepr['mths_since_earliest_cr_line'].max()))), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delinq_2yrs variable\n",
    "# We calculate weight of evidence\n",
    "df_temp12 = woe_ordered_continuous(df_inputs_prepr, 'delinq_2yrs', df_targets_prepr)\n",
    "df_temp12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: 0, 1-3, >=4\n",
    "df_inputs_prepr['delinq_2yrs:0'] = np.where((df_inputs_prepr['delinq_2yrs'] == 0), 1, 0)\n",
    "df_inputs_prepr['delinq_2yrs:1-3'] = np.where((df_inputs_prepr['delinq_2yrs'] >= 1) & (df_inputs_prepr['delinq_2yrs'] <= 3), 1, 0)\n",
    "df_inputs_prepr['delinq_2yrs:>=4'] = np.where((df_inputs_prepr['delinq_2yrs'] >= 9), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inq_last_6mths variable\n",
    "# We calculate weight of evidence.\n",
    "df_temp13 = woe_ordered_continuous(df_inputs_prepr, 'inq_last_6mths', df_targets_prepr)\n",
    "df_temp13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: 0, 1 - 2, 3 - 6, > 6\n",
    "df_inputs_prepr['inq_last_6mths:0'] = np.where((df_inputs_prepr['inq_last_6mths'] == 0), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:1-2'] = np.where((df_inputs_prepr['inq_last_6mths'] >= 1) & (df_inputs_prepr['inq_last_6mths'] <= 2), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:3-6'] = np.where((df_inputs_prepr['inq_last_6mths'] >= 3) & (df_inputs_prepr['inq_last_6mths'] <= 6), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:>6'] = np.where((df_inputs_prepr['inq_last_6mths'] > 6), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_acc variable\n",
    "# We calculate weight of evidence.\n",
    "df_temp14 = woe_ordered_continuous(df_inputs_prepr, 'open_acc', df_targets_prepr)\n",
    "df_temp14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp14, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp14.iloc[ : 40, :], 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: '0', '1-3', '4-12', '13-17', '18-22', '23-25', '26-30', '>30'\n",
    "df_inputs_prepr['open_acc:0'] = np.where((df_inputs_prepr['open_acc'] == 0), 1, 0)\n",
    "df_inputs_prepr['open_acc:1-3'] = np.where((df_inputs_prepr['open_acc'] >= 1) & (df_inputs_prepr['open_acc'] <= 3), 1, 0)\n",
    "df_inputs_prepr['open_acc:4-12'] = np.where((df_inputs_prepr['open_acc'] >= 4) & (df_inputs_prepr['open_acc'] <= 12), 1, 0)\n",
    "df_inputs_prepr['open_acc:13-17'] = np.where((df_inputs_prepr['open_acc'] >= 13) & (df_inputs_prepr['open_acc'] <= 17), 1, 0)\n",
    "df_inputs_prepr['open_acc:18-22'] = np.where((df_inputs_prepr['open_acc'] >= 18) & (df_inputs_prepr['open_acc'] <= 22), 1, 0)\n",
    "df_inputs_prepr['open_acc:23-25'] = np.where((df_inputs_prepr['open_acc'] >= 23) & (df_inputs_prepr['open_acc'] <= 25), 1, 0)\n",
    "df_inputs_prepr['open_acc:26-30'] = np.where((df_inputs_prepr['open_acc'] >= 26) & (df_inputs_prepr['open_acc'] <= 30), 1, 0)\n",
    "df_inputs_prepr['open_acc:>=31'] = np.where((df_inputs_prepr['open_acc'] >= 31), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_rec variable\n",
    "# We calculate weight of evidence\n",
    "df_temp15 = woe_ordered_continuous(df_inputs_prepr, 'pub_rec', df_targets_prepr)\n",
    "df_temp15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp15, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: '0-2', '3-4', '>=5'\n",
    "df_inputs_prepr['pub_rec:0-2'] = np.where((df_inputs_prepr['pub_rec'] >= 0) & (df_inputs_prepr['pub_rec'] <= 2), 1, 0)\n",
    "df_inputs_prepr['pub_rec:3-4'] = np.where((df_inputs_prepr['pub_rec'] >= 3) & (df_inputs_prepr['pub_rec'] <= 4), 1, 0)\n",
    "df_inputs_prepr['pub_rec:>=5'] = np.where((df_inputs_prepr['pub_rec'] >= 5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_acc variable\n",
    "df_inputs_prepr['total_acc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['total_acc_factor'] = pd.cut(df_inputs_prepr['total_acc'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence\n",
    "df_temp16 = woe_ordered_continuous(df_inputs_prepr, 'total_acc_factor', df_targets_prepr)\n",
    "df_temp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp16, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: '<=27', '28-51', '>51'\n",
    "df_inputs_prepr['total_acc:<=27'] = np.where((df_inputs_prepr['total_acc'] <= 27), 1, 0)\n",
    "df_inputs_prepr['total_acc:28-51'] = np.where((df_inputs_prepr['total_acc'] >= 28) & (df_inputs_prepr['total_acc'] <= 51), 1, 0)\n",
    "df_inputs_prepr['total_acc:>=52'] = np.where((df_inputs_prepr['total_acc'] >= 52), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_now_delinq variable\n",
    "# We calculate weight of evidence.\n",
    "df_temp17 = woe_ordered_continuous(df_inputs_prepr, 'acc_now_delinq', df_targets_prepr)\n",
    "df_temp17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values\n",
    "plot_by_woe(df_temp17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: '0', '>=1'\n",
    "df_inputs_prepr['acc_now_delinq:0'] = np.where((df_inputs_prepr['acc_now_delinq'] == 0), 1, 0)\n",
    "df_inputs_prepr['acc_now_delinq:>=1'] = np.where((df_inputs_prepr['acc_now_delinq'] >= 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rev_hi_lim variable\n",
    "df_inputs_prepr['total_rev_hi_lim'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 2000 categories by its values.\n",
    "df_inputs_prepr['total_rev_hi_lim_factor'] = pd.cut(df_inputs_prepr['total_rev_hi_lim'], 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp18 = woe_ordered_continuous(df_inputs_prepr, 'total_rev_hi_lim_factor', df_targets_prepr)\n",
    "df_temp18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp18.iloc[: 50, : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories:'<=5K', '5K-10K', '10K-20K', '20K-30K', '30K-40K', '40K-55K', '55K-95K', '>95K'\n",
    "df_inputs_prepr['total_rev_hi_lim:<=5K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] <= 5000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:5K-10K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 5000) & (df_inputs_prepr['total_rev_hi_lim'] <= 10000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:10K-20K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 10000) & (df_inputs_prepr['total_rev_hi_lim'] <= 20000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:20K-30K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 20000) & (df_inputs_prepr['total_rev_hi_lim'] <= 30000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:30K-40K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 30000) & (df_inputs_prepr['total_rev_hi_lim'] <= 40000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:40K-55K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 40000) & (df_inputs_prepr['total_rev_hi_lim'] <= 55000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:55K-95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 55000) & (df_inputs_prepr['total_rev_hi_lim'] <= 95000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:>95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 95000), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installment variable\n",
    "df_inputs_prepr['installment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['installment_factor'] = pd.cut(df_inputs_prepr['installment'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate weight of evidence.\n",
    "df_temp19 = woe_ordered_continuous(df_inputs_prepr, 'installment_factor', df_targets_prepr)\n",
    "df_temp19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp19, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual_inc variable\n",
    "df_inputs_prepr['annual_inc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr['annual_inc_factor'] = pd.cut(df_inputs_prepr['annual_inc'], 50)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp20 = woe_ordered_continuous(df_inputs_prepr, 'annual_inc_factor', df_targets_prepr)\n",
    "df_temp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the initial ‘annual income’ variable into 50 categories doesn't work well for fine classing because there are a lot of people with low income and very few people with high income.\n",
    "# Thus, we do fine-classing using the 'cut' method, we split the variable into 100 categories by its values.\n",
    "df_inputs_prepr['annual_inc_factor'] = pd.cut(df_inputs_prepr['annual_inc'], 100)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp20 = woe_ordered_continuous(df_inputs_prepr, 'annual_inc_factor', df_targets_prepr)\n",
    "df_temp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial examination shows that there are too few individuals with large income and too many with small income.\n",
    "# Hence, we are going to have one category for more than 150K, and we are going to apply our approach to determine\n",
    "# the categories of everyone with 140k or less.\n",
    "df_inputs_prepr_temp = df_inputs_prepr.loc[df_inputs_prepr['annual_inc'] <= 140000, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr_temp[\"annual_inc_factor\"] = pd.cut(df_inputs_prepr_temp['annual_inc'], 50)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp20 = woe_ordered_continuous(df_inputs_prepr_temp, 'annual_inc_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
    "df_temp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp20, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WoE is monotonically decreasing with income, so we split income in 10 equal categories, each with width of 15k.\n",
    "df_inputs_prepr['annual_inc:<20K'] = np.where((df_inputs_prepr['annual_inc'] <= 20000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:20K-30K'] = np.where((df_inputs_prepr['annual_inc'] > 20000) & (df_inputs_prepr['annual_inc'] <= 30000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:30K-40K'] = np.where((df_inputs_prepr['annual_inc'] > 30000) & (df_inputs_prepr['annual_inc'] <= 40000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:40K-50K'] = np.where((df_inputs_prepr['annual_inc'] > 40000) & (df_inputs_prepr['annual_inc'] <= 50000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:50K-60K'] = np.where((df_inputs_prepr['annual_inc'] > 50000) & (df_inputs_prepr['annual_inc'] <= 60000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:60K-70K'] = np.where((df_inputs_prepr['annual_inc'] > 60000) & (df_inputs_prepr['annual_inc'] <= 70000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:70K-80K'] = np.where((df_inputs_prepr['annual_inc'] > 70000) & (df_inputs_prepr['annual_inc'] <= 80000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:80K-90K'] = np.where((df_inputs_prepr['annual_inc'] > 80000) & (df_inputs_prepr['annual_inc'] <= 90000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:90K-100K'] = np.where((df_inputs_prepr['annual_inc'] > 90000) & (df_inputs_prepr['annual_inc'] <= 100000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:100K-120K'] = np.where((df_inputs_prepr['annual_inc'] > 100000) & (df_inputs_prepr['annual_inc'] <= 120000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:120K-140K'] = np.where((df_inputs_prepr['annual_inc'] > 120000) & (df_inputs_prepr['annual_inc'] <= 140000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:>140K'] = np.where((df_inputs_prepr['annual_inc'] > 140000), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_delinq variable\n",
    "# We have to create one category for missing values and do fine and coarse classing for the rest.\n",
    "df_inputs_prepr_temp = df_inputs_prepr[pd.notnull(df_inputs_prepr['mths_since_last_delinq'])]\n",
    "df_inputs_prepr_temp['mths_since_last_delinq_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_delinq'], 50)\n",
    "\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp21 = woe_ordered_continuous(df_inputs_prepr_temp, 'mths_since_last_delinq_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
    "df_temp21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp21, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: Missing, 0-3, 4-30, 31-56, >=57\n",
    "df_inputs_prepr['mths_since_last_delinq:Missing'] = np.where((df_inputs_prepr['mths_since_last_delinq'].isnull()), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:0-3'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 0) & (df_inputs_prepr['mths_since_last_delinq'] <= 3), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:4-30'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 4) & (df_inputs_prepr['mths_since_last_delinq'] <= 30), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:31-56'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 31) & (df_inputs_prepr['mths_since_last_delinq'] <= 56), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:>=57'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 57), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dti variable\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 100 categories by its values.\n",
    "df_inputs_prepr['dti_factor'] = pd.cut(df_inputs_prepr['dti'], 100)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp22 = woe_ordered_continuous(df_inputs_prepr, 'dti_factor', df_targets_prepr)\n",
    "df_temp22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp22, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly to income, initial examination shows that most values are lower than 200.\n",
    "# Hence, we are going to have one category for more than 35, and we are going to apply our approach to determine\n",
    "# the categories of everyone with 150k or less.\n",
    "df_inputs_prepr_temp = df_inputs_prepr.loc[df_inputs_prepr['dti'] <= 35, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr_temp['dti_factor'] = pd.cut(df_inputs_prepr_temp['dti'], 50)\n",
    "\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp22 = woe_ordered_continuous(df_inputs_prepr_temp, 'dti_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
    "df_temp22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp22, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories:\n",
    "df_inputs_prepr['dti:<=1.4'] = np.where((df_inputs_prepr['dti'] <= 1.4), 1, 0)\n",
    "df_inputs_prepr['dti:1.4-3.5'] = np.where((df_inputs_prepr['dti'] > 1.4) & (df_inputs_prepr['dti'] <= 3.5), 1, 0)\n",
    "df_inputs_prepr['dti:3.5-7.7'] = np.where((df_inputs_prepr['dti'] > 3.5) & (df_inputs_prepr['dti'] <= 7.7), 1, 0)\n",
    "df_inputs_prepr['dti:7.7-10.5'] = np.where((df_inputs_prepr['dti'] > 7.7) & (df_inputs_prepr['dti'] <= 10.5), 1, 0)\n",
    "df_inputs_prepr['dti:10.5-16.1'] = np.where((df_inputs_prepr['dti'] > 10.5) & (df_inputs_prepr['dti'] <= 16.1), 1, 0)\n",
    "df_inputs_prepr['dti:16.1-20.3'] = np.where((df_inputs_prepr['dti'] > 16.1) & (df_inputs_prepr['dti'] <= 20.3), 1, 0)\n",
    "df_inputs_prepr['dti:20.3-21.7'] = np.where((df_inputs_prepr['dti'] > 20.3) & (df_inputs_prepr['dti'] <= 21.7), 1, 0)\n",
    "df_inputs_prepr['dti:21.7-22.4'] = np.where((df_inputs_prepr['dti'] > 21.7) & (df_inputs_prepr['dti'] <= 22.4), 1, 0)\n",
    "df_inputs_prepr['dti:22.4-35'] = np.where((df_inputs_prepr['dti'] > 22.4) & (df_inputs_prepr['dti'] <= 35), 1, 0)\n",
    "df_inputs_prepr['dti:>35'] = np.where((df_inputs_prepr['dti'] > 35), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_record variable\n",
    "# We have to create one category for missing values and do fine and coarse classing for the rest.\n",
    "#sum(loan_data_temp['mths_since_last_record'].isnull())\n",
    "\n",
    "df_inputs_prepr_temp = df_inputs_prepr[pd.notnull(df_inputs_prepr['mths_since_last_record'])]\n",
    "\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
    "df_inputs_prepr_temp['mths_since_last_record_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_record'], 50)\n",
    "\n",
    "# We calculate weight of evidence.\n",
    "df_temp23 = woe_ordered_continuous(df_inputs_prepr_temp, 'mths_since_last_record_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
    "df_temp23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the weight of evidence values.\n",
    "plot_by_woe(df_temp23, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following Categories: 'Missing', '0-2', '3-20', '21-31', '32-80', '81-86', '>86'\n",
    "df_inputs_prepr['mths_since_last_record:Missing'] = np.where((df_inputs_prepr['mths_since_last_record'].isnull()), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:0-2'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 0) & (df_inputs_prepr['mths_since_last_record'] <= 2), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:3-20'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 3) & (df_inputs_prepr['mths_since_last_record'] <= 20), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:21-31'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 21) & (df_inputs_prepr['mths_since_last_record'] <= 31), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:32-80'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 32) & (df_inputs_prepr['mths_since_last_record'] <= 80), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:81-86'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 81) & (df_inputs_prepr['mths_since_last_record'] <= 86), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:>86'] = np.where((df_inputs_prepr['mths_since_last_record'] > 86), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING THE PREPROCESS TRAIN AND TEST DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
